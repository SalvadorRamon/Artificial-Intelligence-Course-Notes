# Temporal Pattern Recognition
*This whole note is under review. The following text is only a draft.*

[Machine Learning](machine-learning.md) helps us to identify patterns in static data, but it's not directly suited to deal with patterns in data that varies in time.

## Dynamic Time Warping
**Dynamic time warping (DTW)** is a technique to measure the similarity between two **time series**. A time series is a sequence of data points ordered by time, e.g the values of a stock in the stock exchange during some period. We could measure the difference between two time series by simply summing up the differences between the series in each time unit, but that would not account for differences in **phase**.

DTW is a more smart approach that tries to account for the phase. Instead of summing up the differences between the points of the same time unit, we sum the differences between the minimal differences between the data points.

### Markov Processes
A **Markov process** is a statistical model that can be applied to the problem of finding patterns in temporal data. It's modeled as follows. First, we assume time is discrete and represented by the set of positive integers (*t = 1, 2, 3 ...*). Second, we assume data at time *t* comes from a discrete random variable *X<sub>t<sub>* with a domain *S = {s<sub>1</sub>, ... , s<sub>n</sub>}*, and the probability of each outcome depends on the past outcomes. Then, we make the **Markov assumption**: the number of previous outcomes that influences on the probability of the current outcome is a fixed positive integer *k*. If *k=1*, we have a **first-order Markov process** that can represented as a Bayesian network.

<p align="center"><img src="images\markov_process.png" title="First-order Markov process"/></p>

We assume the process is **stationary**, i.e there is a single conditional probability table that holds the values of *P(X<sub>t</sub> | X<sub>t-1</sub>)* and is used for every random variable in the model. The process is called stationary because conditional probabilities are the same regardless of the time *t*.

Finally, we define the initial probabilities of each element of *S*, i.e. *P(X<sub>1</sub>)*. These will be used to calculate the probability of a element to be in the first position of the sequence.

>**Markovian nomenclature**
>
> A more precise term for what we call here a Markov process would be **stationary discrete-time first-order Markov chain**. The "chain" part comes from the assumption of discrete random variables, which make possible to represent the problem as a Bayesian network (the "chain").
>
> There are extensions of the Markov process that modify each one of the assumptions made here (stationarity, discrete time and discrete random variables). So a Markov process can also be defined as a broader term that encompasses all those variants. Unfortunately, the nomenclature is not standardized in the literature, so you may find the term "Markov process" referring to one specific subtype, as we have done here for simplicity.

Once we define a Markov process, we can calculate the probability of the sequence *O = o<sub>1</sub>,..., o<sub>m</sub>*, where *o<sub>i</sub> âˆˆ S*, being generated by the model. It's given by:

<p align="center"><img src="https://latex.codecogs.com/svg.latex?P(O|model)=P(X_1=o_1)\prod_{t=2}^mP(X_t=o_t|X_{t-1}=o_{t-1})"/></p>

A classical application of Markov processes is in **natural language processing (NLP)**. For example, we can imagine that words in a sentence are a sequence generated by a Markov process. The conditional probability table of that process could be built based on a training corpus of text, by estimating the conditional probabilities as the frequencies of the words that precedes a given word. The number of preceding words we choose to consider defines the order of the Markov process. For the first-order Markov process, we choose one preceding word, second-order for 2 words and so on up to the *n<sup>th</sup>*-order. These are called, respectively, **unigram**, **bigram** and **n-gram** models in the NLP jargon.

In such a model, we can suggest the next word in a text (a common feature of text processors) by answering "Given the sentence *W = w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>*, does what word *w<sub>n+1</sub>* produce the sentence *W<sup>\*</sup> = w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>, w<sub>n+1</sub>* with the highest *P(W<sup>\*</sup>)*?".

## Hidden Markov Models
Markov process are only useful when the pattern in the sequence can be directly observed. In our NLP example, we can observe the words of a sentence. But there are interesting problems that we can't observe the sequence directly, but we can observe a related random variable. For example, in gesture language recognition, we are usually interested in the words behind the gestures, but all we can see are the gestures themselves. **Hidden Markov Model** is a extension of the Markov process that deal with those cases.








We assume the process is **stationary**, i.e there is a fixed *n x n* **transition matrix** *A* that holds the conditional probabilities of every random variable *X<sub>t</sub>* in the model, where *n* is the size of the random variables' domain (denoted as *S = {S<sub>1</sub>, ... , S<sub>n</sub>}*). The process is called stationary because *A* is the same regardless of the time *t*. In mathematical notation:

<p align="center"><img src="https://latex.codecogs.com/svg.latex?A=\begin{bmatrix}a_{11}&\dots&a_{1n}\\\vdots&\ddots%20&\\a_{n1}&&%20a_{nn}\end{bmatrix},a_{ij}=P(X_t=S_j|X_{t-1}=S_i)"/></p>

And since *A* holds the full conditional probability of a random variable:

<p align="center"><img src="https://latex.codecogs.com/svg.latex?\sum_{j=1}^na_{ij}=1"/></p>

Finally, we define the initial probabilities of each element of *S*, i.e. *P(X<sub>1</sub> = S<sub>i</sub>)*. These will be used to calculate the probability of a element to be in the first position of the sequence.